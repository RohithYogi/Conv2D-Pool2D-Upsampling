{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "O1P2fQDwbisH",
    "outputId": "28d9a898-01a5-4525-e33d-c06bb16d22bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K \n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard\n",
    "from tensorflow.python.keras.engine.base_layer import Layer\n",
    "from keras import optimizers\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D ,Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eb0Wy2fb2qaq"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = x_train.astype('float32') / 255.\n",
    "X_test = x_test.astype('float32') / 255.\n",
    "X_train = np.reshape(X_train, (len(X_train), 28, 28, 1))    # adapt this if using 'channels_first' image data format\n",
    "X_test = np.reshape(X_test, (len(X_test), 28, 28, 1))       # adapt this if using 'channels_first' image data format\n",
    "\n",
    "X_train = np.reshape(X_train, (len(X_train), 28,28, 1))    # adapt this if using 'channels_first' image data format\n",
    "X_test = np.reshape(X_test, (len(X_test), 28,28, 1))       # adapt this if using 'channels_first' image data format\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NoUFLn9P3RXG"
   },
   "outputs": [],
   "source": [
    "b = np.zeros((len(y_test),10))\n",
    "for i in range(0,len(y_test)):\n",
    "    b[i][y_test[i]]+=1\n",
    "y_test = b\n",
    "\n",
    "a = np.zeros((len(y_train),10))\n",
    "for i in range(0,len(y_train)):\n",
    "    a[i][y_train[i]]+=1\n",
    "y_train = a  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "id": "v4Xrs_8Ds1Ec",
    "outputId": "e8d8de37-7176-4deb-875e-6a45ba5f8d93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 23s 376us/step - loss: 0.0940 - val_loss: 0.0391\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 32s 534us/step - loss: 0.0332 - val_loss: 0.0265\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 24s 404us/step - loss: 0.0242 - val_loss: 0.0214\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 20s 329us/step - loss: 0.0200 - val_loss: 0.0177\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 19s 312us/step - loss: 0.0175 - val_loss: 0.0154\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 24s 395us/step - loss: 0.0158 - val_loss: 0.0151\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 24s 405us/step - loss: 0.0146 - val_loss: 0.0143\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 20s 333us/step - loss: 0.0138 - val_loss: 0.0127\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 16s 272us/step - loss: 0.0129 - val_loss: 0.0126\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 16s 263us/step - loss: 0.0122 - val_loss: 0.0123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5186e92908>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_img = Input(shape=(28, 28, 1))    # adapt this if using 'channels_first' image data format\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x1 = MaxPooling2D((2, 2), padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x1)\n",
    "flat = Flatten()(encoded)\n",
    "decoded = Dense(10, activation='softmax')(flat)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='Adam', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.fit(X_train, y_train, epochs=10, batch_size=128, shuffle=True, validation_data=(X_test, y_test),\n",
    "                callbacks=[TensorBoard(log_dir='conv_autoencoder')], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DNc8cJaps5xm"
   },
   "outputs": [],
   "source": [
    "layer_weights = []\n",
    "for layer in autoencoder.layers: \n",
    "    if(len(layer.get_weights())>0):\n",
    "        layer_weights.append((layer.get_weights())[0])\n",
    "\n",
    "\n",
    "wei1 = layer_weights[0]\n",
    "wei2 = layer_weights[1]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pDvh5ejUbisw"
   },
   "outputs": [],
   "source": [
    "def ReLU(X):\n",
    "    return tf.maximum(X, np.zeros_like(X))\n",
    "\n",
    "def softmax(X):\n",
    "    return tf.exp(X)/tf.reduce_sum(tf.exp(X), 1)\n",
    "\n",
    "def tanh(X):\n",
    "    return tf.tanh(X)\n",
    "\n",
    "def sigmoid(X):\n",
    "    return 1 / (1 + tf.exp(-X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ytMWZWbvbitM"
   },
   "outputs": [],
   "source": [
    "def myConv2D(X, W, filters, kernel_size, strides=1, padding='valid', activation=None, bias=0):\n",
    "\n",
    "    if isinstance(kernel_size, int):\n",
    "        ker_h, ker_w = kernel_size, kernel_size\n",
    "    elif isinstance(kernel_size, tuple):\n",
    "        ker_h, ker_w = kernel_size\n",
    "    else:\n",
    "        raise ValueError('Kernel size should be tuple of ints or an int.')\n",
    "        \n",
    "        \n",
    "    batch , inp_h, inp_w, inp_c = X.shape\n",
    "    if padding == 'valid':\n",
    "        pad = 0\n",
    "    elif padding == 'same':\n",
    "        pad = (ker_h - 1)//2\n",
    "    else:\n",
    "        raise ValueError('Padding '+padding+' is not defined')\n",
    "    \n",
    "    conv_h = (inp_h + 2*pad - ker_h)//strides + 1\n",
    "    conv_w = (inp_w + 2*pad - ker_w)//strides + 1\n",
    "    \n",
    "    X_pad = tf.pad(X, [[0,0],[pad,pad],[pad,pad],[0,0]])\n",
    "    \n",
    "    convolve = []\n",
    "    for x in range(conv_h):\n",
    "        for y in range(conv_w):\n",
    "            c = tf.slice(X_pad, [0, x*strides, y*strides, 0], [-1, ker_h, ker_w, -1])\n",
    "            convolve.append(c)\n",
    "    \n",
    "    X_mat = tf.reshape(tf.stack(convolve), [-1, ker_w*ker_h])\n",
    "#     print(\"X_mat: \", X_mat.shape)\n",
    "    W = W[:,:,0,:]\n",
    "    W_mat = tf.reshape(W, [ker_h*ker_w, filters])\n",
    "    \n",
    "    b = tf.zeros([filters])+bias\n",
    "    \n",
    "    conv = tf.matmul(X_mat, W_mat) + b\n",
    "    conv = tf.transpose(tf.reshape(conv,[conv_h,conv_w,-1,filters]), [2,0,1,3])\n",
    "    \n",
    "    if activation:\n",
    "        activation = activation.lower()\n",
    "        if activation == 'relu':\n",
    "            conv = ReLU(conv)\n",
    "        elif activation == 'softmax':\n",
    "            conv = softmax(conv)\n",
    "        elif activation == 'tanh':\n",
    "            conv = tanh(conv)\n",
    "        elif activation == 'sigmoid':\n",
    "            conv = sigmoid(conv)    \n",
    "        else:\n",
    "            raise ValueError('Unknown activation')\n",
    "            \n",
    "    \n",
    "    return conv\n",
    "    \n",
    "# x1 = myConv2D(input_batch, 16, (3,3), padding = 'same', activation = 'relu')\n",
    "# print(x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eUJuyaaZbitY"
   },
   "outputs": [],
   "source": [
    "def myMaxPool2D(X, kernel_size, strides=2, padding='valid'):\n",
    "    if isinstance(kernel_size, int):\n",
    "        ker_h, ker_w = kernel_size, kernel_size\n",
    "    elif isinstance(kernel_size, tuple):\n",
    "        ker_h, ker_w = kernel_size\n",
    "    else:\n",
    "        raise ValueError('Kernel size should be tuple of ints or an int.')\n",
    "        \n",
    "    _, inp_h, inp_w, inp_c = X.shape\n",
    "    if padding == 'valid':\n",
    "        pad = 0\n",
    "    elif padding == 'same':\n",
    "        pad = (ker_h - 1)//2\n",
    "    else:\n",
    "        raise ValueError('Padding '+padding+' is not defined')\n",
    "    \n",
    "    pool_h = (inp_h + 2*pad - ker_h)//strides + 1 \n",
    "    pool_w = (inp_w + 2*pad - ker_w)//strides + 1\n",
    "    \n",
    "    X_pad = tf.pad(X, [[0,0],[pad,pad],[pad,pad],[0,0]])\n",
    "    \n",
    "    pooling = []\n",
    "    for x in range(pool_h):\n",
    "        for y in range(pool_w):\n",
    "            p = tf.slice(X_pad, [0, x*strides, y*strides, 0], [-1, ker_h, ker_w, -1])\n",
    "            pooling.append(p)\n",
    "    \n",
    "    X_mat = tf.reshape(tf.stack(pooling), [-1, ker_w*ker_h])\n",
    "    \n",
    "    pool = tf.reduce_max(tf.reshape(X_mat, [pool_h, pool_w, -1, ker_h*ker_w, int(inp_c)]), axis = 3)\n",
    "    return tf.transpose(pool, [2,0,1,3])\n",
    "\n",
    "# x2 = myMaxPool2D(x1, (2,2), strides = 2, padding='valid')\n",
    "# print(x2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KbfauaBlbitk"
   },
   "outputs": [],
   "source": [
    "def myUpSampling2D(X, kernel_size, data_format='channels_last', interpolation='nearest'):\n",
    "    if isinstance(kernel_size, int):\n",
    "        ker_h, ker_w = kernel_size, kernel_size\n",
    "    elif isinstance(kernel_size, tuple):\n",
    "        ker_h, ker_w = kernel_size\n",
    "    else:\n",
    "        raise ValueError('Kernel size should be tuple of ints or an int.')\n",
    "        \n",
    "    if (data_format=='channels_last'):\n",
    "        n, inp_h, inp_w, inp_c = X.shape\n",
    "    elif (data_format=='channels_first'):\n",
    "        n, inp_c, inp_h, inp_w = X.shape\n",
    "    else:\n",
    "        raise ValueError('Data format is not valid.')\n",
    "    \n",
    "    print(type(n))\n",
    "    out_h = inp_h*ker_h\n",
    "    out_w = inp_w*ker_w\n",
    "    \n",
    "    l = []\n",
    "    img = 0\n",
    "    \n",
    "    while img < int(n):\n",
    "        i = 0\n",
    "        while i < int(inp_h):\n",
    "            temp = []\n",
    "            j = 0\n",
    "            while j < int(inp_w):\n",
    "                p = tf.slice(X, [img,i,j,0], [1,1,1,1])\n",
    "                for x in range(ker_w):\n",
    "                    temp.append(p)\n",
    "                j+=1\n",
    "            for x in range(ker_h):\n",
    "                for c in temp:\n",
    "                    l.append(c)\n",
    "            i+=1\n",
    "        img+=1\n",
    "    X_mat = tf.reshape(tf.stack(l), [1, out_h, out_w])\n",
    "    \n",
    "    l = []\n",
    "    for i in range(int(inp_c)):\n",
    "        l.append(X_mat)\n",
    "        \n",
    "    X_mat = tf.reshape(tf.stack(l), [1, out_h, out_w, int(inp_c)])\n",
    "    \n",
    "#     print(X_mat.shape)\n",
    "    return X_mat\n",
    "            \n",
    "# myUpSampling2D(x2, (2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z7ZlGp6JnerI"
   },
   "outputs": [],
   "source": [
    "def fully_connected(pool_out):\n",
    "    flattened_vector = pool_out.flatten()\n",
    "    return np.matmul(flattened_vector, wei2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "SekrjzYFbit-",
    "outputId": "a7be8cf4-c212-4013-ca16-a2ad737f261d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hai1 (10000, 28, 28, 16)\n",
      "hai2 (10000, 14, 14, 16)\n"
     ]
    }
   ],
   "source": [
    "input_img = X_test\n",
    "x = myConv2D(input_img, wei1, 16, (3,3), activation = 'relu', padding = 'same')\n",
    "print(\"hai1\",x.shape)\n",
    "x = myMaxPool2D(x, (2,2), padding = 'same')\n",
    "print(\"hai2\",x.shape)\n",
    "encoded1 = myMaxPool2D(x, (2,2), padding = 'same')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X4WxjLD9hZz1"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "W1 = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "array = encoded1.eval(session=sess)\n",
    "# print (array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qEVEjQc0xXcX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=[]\n",
    "for i in array:\n",
    "  pred.append(fully_connected(i))\n",
    "\n",
    "y_pred1 = np.array(pred)\n",
    "y_pred1.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "QikxX2g0z7__",
    "outputId": "d21cc512-e03b-4843-ccbf-66a647f6bddd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UCG5pj6ibiuj"
   },
   "outputs": [],
   "source": [
    "y_pred = autoencoder.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "C0TrQnaz_0nr",
    "outputId": "3bbf2560-9c00-4dc8-d1e9-49a0985e79c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99969230622\n",
      "0.997107608775\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_test, y_pred))\n",
    "print(roc_auc_score(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Part1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
